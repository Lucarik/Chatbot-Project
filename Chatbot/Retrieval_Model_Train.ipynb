{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3082a278-3fe1-4d5b-8c3e-d4d23177469a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.nn import init\n",
    "import torch.nn.utils.rnn \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import datetime\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52deebc4-d0a4-45fe-bb0e-1e0e4808741e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d5a216-b218-407f-86c2-8f3e4012e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dialog pairs consist of [context, response, label]\n",
    "def get_dialog_pairs(dataset, evalset):\n",
    "    dataset_length = len(dataset)\n",
    "    dialog_pairs = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip() \n",
    "            if not inputLine or not isinstance(inputLine, str): \n",
    "                inputLine = 'Nothing'\n",
    "            if isinstance(dataset[i][j], str):\n",
    "                targetLine = dataset[i][j].strip()\n",
    "            else:\n",
    "                targetLine = dataset[i][j]['text'].strip() \n",
    "            if not targetLine or not isinstance(targetLine, str): \n",
    "                targetLine = 'Nothing'\n",
    "            if isinstance(inputLine, str) and isinstance(targetLine, str) and inputLine and targetLine:\n",
    "                if evalset[i] >= 2:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "                inputLine = normalizeString(inputLine)\n",
    "                targetLine = normalizeString(targetLine)\n",
    "                dialog_pairs.append([inputLine, targetLine, label])\n",
    "\n",
    "    return dialog_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9a9fd00-e868-4da2-bb9e-78b64982b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of individual sentences\n",
    "def get_dialog(dataset):\n",
    "    dataset_length = len(dataset)\n",
    "    dialog = []\n",
    "    for i in range(dataset_length):\n",
    "        conv_length = len(dataset[i])\n",
    "        \n",
    "        for j in range(1,conv_length):\n",
    "            if isinstance(dataset[i][j-1], str):\n",
    "                inputLine = dataset[i][j-1].strip()\n",
    "            else:\n",
    "                inputLine = dataset[i][j-1]['text'].strip()\n",
    "                \n",
    "            if not isinstance(inputLine, str) or not inputLine or len(inputLine.split()) <= 0: \n",
    "                continue\n",
    "            inputLine = normalizeString(inputLine)\n",
    "            dialog.append([inputLine])\n",
    "\n",
    "    return dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cfe3d66-7dd0-414d-8e07-80c5f0fec98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4cd1fe2-b3ce-4c5b-abcd-edd364eac2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    if isinstance(s, str): \n",
    "        s = unicodeToAscii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "        s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e9ecb98-4d83-4cc6-90dd-c060297ae4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_list(list):\n",
    "    random.shuffle(list)\n",
    "\n",
    "def create_vocab(dialog):\n",
    "    vocab = []\n",
    "    word_freq = {}\n",
    "    \n",
    "    for sentence in dialog:\n",
    "        sen = \"\".join(c for c in sentence)\n",
    "        train_words = str(sen).split(\" \")\n",
    "        \n",
    "        for word in train_words:\n",
    "          \n",
    "            if word.lower() not in vocab:\n",
    "                vocab.append(word.lower())         \n",
    "                       \n",
    "            if word.lower() not in word_freq:\n",
    "                word_freq[word.lower()] = 1\n",
    "            else:\n",
    "                #type(word)\n",
    "                word_freq[word] += 1\n",
    "    \n",
    "    word_freq_sorted = sorted(word_freq.items(), key=lambda item: item[1], reverse=True)\n",
    "    vocab = [\"<UNK>\"] + [pair[0] for pair in word_freq_sorted]\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def create_word_to_id(vocab):             \n",
    "    word_to_id = {word: id for id, word in enumerate(vocab)}\n",
    "    \n",
    "    return word_to_id\n",
    "\n",
    "\n",
    "def create_id_to_vec(word_to_id, glovefile): \n",
    "    lines = open(glovefile, 'r', encoding='utf-8').readlines()\n",
    "    id_to_vec = {}\n",
    "    vector = None\n",
    "    \n",
    "    for line in lines:\n",
    "        word = line.split()[0]\n",
    "        vector = np.array(line.split()[1:], dtype='float32') #32\n",
    "        \n",
    "        if word in word_to_id:\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(vector))\n",
    "            \n",
    "    for word, id in word_to_id.items(): \n",
    "        if word_to_id[word] not in id_to_vec:\n",
    "            v = np.zeros(*vector.shape, dtype='float32')\n",
    "            v[:] = np.random.randn(*v.shape)*0.01\n",
    "            id_to_vec[word_to_id[word]] = torch.FloatTensor(torch.from_numpy(v))\n",
    "            \n",
    "    embedding_dim = id_to_vec[0].shape[0]\n",
    "    \n",
    "    return id_to_vec, embedding_dim\n",
    "\n",
    "def load_id(sentence, word_to_id):\n",
    "    sentence_ids = []\n",
    "\n",
    "    max_sentence_len = 160\n",
    "    \n",
    "    sentence_words = sentence.split()\n",
    "    if len(sentence_words) > max_sentence_len:\n",
    "        sentence_words = sentence_words[:max_sentence_len]\n",
    "    for word in sentence_words:\n",
    "        if word in word_to_id:\n",
    "            sentence_ids.append(word_to_id[word])\n",
    "        else: \n",
    "            sentence_ids.append(0) #UNK\n",
    "\n",
    "    return sentence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0398a8b1-6101-474f-8391-4e7c4e0ff633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.sentences = []\n",
    "        self.word2id = {}\n",
    "        self.id2vec = None\n",
    "        \n",
    "    def save(self):\n",
    "        torch.save({\n",
    "                'voc_dict': self.__dict__,\n",
    "            }, os.path.join('saveDir', 'save_voc2.tar'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.__dict__ = checkpoint['voc_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8082293c-3825-4d41-8d06-d2d795254f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temp:\n",
    "    def __init__(self):\n",
    "        self.training = []\n",
    "        self.validation = []\n",
    "        self.voc = []\n",
    "        \n",
    "    def save(self):\n",
    "        torch.save({\n",
    "                'temp_dict': self.__dict__,\n",
    "            }, os.path.join('saveDir', 'save_temp.tar'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        self.__dict__ = checkpoint['temp_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "958a2994-ea8e-4934-8822-6dde577d4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(embedding_dim):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    raw_dataset = load_dataset(\"conv_ai_2\")\n",
    "    raw_dataset1 = load_dataset(\"daily_dialog\")\n",
    "    train_dataset = raw_dataset[\"train\"]\n",
    "    train_dataset1 = raw_dataset1[\"train\"]\n",
    "    raw_dialog_list = train_dataset[\"dialog\"]\n",
    "    raw_dialog_list1 = train_dataset1[\"dialog\"]\n",
    "    \n",
    "    eval_list = train_dataset[\"eval_score\"]\n",
    "    eval_list1 = [2 for i in range(len(raw_dialog_list1))]\n",
    "    \n",
    "    dialog_pairs = get_dialog_pairs(raw_dialog_list, eval_list)\n",
    "    dialog_pairs1 = get_dialog_pairs(raw_dialog_list1, eval_list1)\n",
    "    dialog_pairs.extend(dialog_pairs1)\n",
    "    only_dialog_pairs = []\n",
    "    for i in range(len(dialog_pairs)):\n",
    "        only_dialog_pairs.append(dialog_pairs[i][0:2])\n",
    "    \n",
    "    dialog_indiv = get_dialog(raw_dialog_list)\n",
    "    dialog_indiv1 = get_dialog(raw_dialog_list1)\n",
    "    dialog_indiv.extend(dialog_indiv1)\n",
    "    \n",
    "    trimmed_sentences = []\n",
    "    for s in dialog_indiv:\n",
    "        if isinstance(s[0], str) and len(s[0].split()) < 15:\n",
    "            trimmed_sentences.append(s)\n",
    "    \n",
    "    vocab = create_vocab(trimmed_sentences)\n",
    "    voc = Voc()\n",
    "    voc.vocab = vocab\n",
    "    voc.sentences = trimmed_sentences\n",
    "    shuffle_list(dialog_pairs)\n",
    "            \n",
    "    # Trim pairs to max 14 words and under\n",
    "    trimmed_pairs = []\n",
    "    for pair in dialog_pairs:\n",
    "        if isinstance(pair[0], str) and len(pair[0].split()) < 15 and isinstance(pair[1], str) and len(pair[1].split()) < 15:\n",
    "            trimmed_pairs.append(pair)\n",
    "    \n",
    "    #training_data = trimmed_pairs\n",
    "    training_data = trimmed_pairs[:-(int(len(trimmed_pairs) / 20))]\n",
    "    \n",
    "    word_to_id = create_word_to_id(vocab)\n",
    "    voc.word2id = word_to_id\n",
    "    id_to_vec, emb_dim = create_id_to_vec(word_to_id, 'saveDir/GloVe/glove.6B.%dd.txt' %embedding_dim)\n",
    "    voc.id2vec = id_to_vec\n",
    "    voc.save()\n",
    "\n",
    "    validation_data = trimmed_pairs[-(int(len(trimmed_pairs) / 20)):]\n",
    "    \n",
    "    return training_data, validation_data, voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df6b24aa-0230-4bce-b16b-3ac6a1bee353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LEncoder(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, layers, bi_dir, vocab_size, id_to_vec, dropout):\n",
    "        super(LEncoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.layers = layers\n",
    "        self.direction = bi_dir\n",
    "        self.id_to_vec = id_to_vec\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(input_size=self.embed_size, hidden_size=self.hidden_size, dropout=self.dropout)\n",
    "        \n",
    "        embedding_weights = torch.FloatTensor(self.vocab_size, self.hidden_size)\n",
    "        embedding_weights = embedding_weights.to(device)\n",
    "        for id, vec in self.id_to_vec.items():\n",
    "            embedding_weights[id] = vec\n",
    "\n",
    "        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad = False)\n",
    "\n",
    "    def initHiddenCell(self):\n",
    "        rand_hidden = autograd.Variable(torch.randn(1, 1, self.hidden_size))\n",
    "        rand_cell = autograd.Variable(torch.randn(1, 1, self.hidden_size))\n",
    "        return rand_hidden, rand_cell\n",
    "\n",
    "    def forward(self, input_id, hidden, cell):\n",
    "        tensor_input = torch.LongTensor([input_id])\n",
    "        tensor_input = tensor_input.to(device)\n",
    "        embed_input = self.embedding(tensor_input).view(1, 1, -1)\n",
    "        output, (hidden, cell) = self.lstm(embed_input, (hidden, cell))\n",
    "        return output, hidden, cell\n",
    "\n",
    "\n",
    "class Dual_Encoder(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(Dual_Encoder, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.input_dim = 5 * self.encoder.hidden_size\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, int(self.input_dim/2)),\n",
    "            nn.Linear(int(self.input_dim/2), 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, s1, s2):\n",
    "\n",
    "        # init hidden, cell\n",
    "        h1, c1 = self.encoder.initHiddenCell()\n",
    "        h2, c2 = self.encoder.initHiddenCell()\n",
    "        h1 = h1.to(device)\n",
    "        c1 = c1.to(device)\n",
    "        h2 = h2.to(device)\n",
    "        c2 = c2.to(device)\n",
    "\n",
    "        for i in range(len(s1)):\n",
    "            v1, h1, c1 = self.encoder(s1[i], h1, c1)\n",
    "\n",
    "        for j in range(len(s2)):\n",
    "            v2, h2, c2 = self.encoder(s2[j], h2, c2)\n",
    "        \n",
    "\n",
    "        # utilize these two encoded vectors\n",
    "        features = torch.cat((v1,torch.abs(v1 - v2),v2,v1*v2, (v1+v2)/2), 2)\n",
    "        output = self.classifier(features)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a118a1e-0821-4455-99c1-68666a1eeeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_model(embed_size, hidden_size, layers, bi_dir, vocab_size, id_to_vec, dropout):\n",
    "\n",
    "    encoder = LEncoder(\n",
    "            embed_size = embed_size,\n",
    "            hidden_size = hidden_size,\n",
    "            layers = layers,\n",
    "            bi_dir = bi_dir,\n",
    "            vocab_size = vocab_size,\n",
    "            id_to_vec = id_to_vec,\n",
    "            dropout = dropout)\n",
    "\n",
    "    dual_encoder = Dual_Encoder(encoder)\n",
    "    \n",
    "    return encoder, dual_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fec9088f-a802-4525-9401-0caf0a9a3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIterAll(training_data, validation_data, voc, c_encoder, learning_rate, l2_penalty, epochs, filename=None):\n",
    "    train_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    best_loss = 10.0\n",
    "    start_epoch = 0\n",
    "    optimizer = torch.optim.Adam(c_encoder.parameters(), lr = learning_rate, weight_decay = l2_penalty)\n",
    "    \n",
    "    if filename:\n",
    "        # If loading checkpoint\n",
    "        print('Loading saved checkpoint')\n",
    "        checkpoint = torch.load(filename)\n",
    "        encoder_sd = checkpoint['en']\n",
    "        encoder_optimizer_sd = checkpoint['opt']\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        train_loss_list = checkpoint['t_loss']\n",
    "        validation_loss_list = checkpoint['v_loss']\n",
    "        voc.__dict__ = checkpoint['voc_dict']\n",
    "        \n",
    "        c_encoder.load_state_dict(encoder_sd)\n",
    "        optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    \n",
    "    loss_weights = autograd.Variable(torch.FloatTensor([3, 1]))\n",
    "    loss_func = torch.nn.CrossEntropyLoss(loss_weights)\n",
    "    loss_func = loss_func.to(device)\n",
    "    total_training_accuracy = 0\n",
    "    best_validation_accuracy = 0\n",
    "    best_training_accuracy = 0\n",
    "    \n",
    "    \n",
    "    word_to_id = voc.word2id\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        # Initializations\n",
    "        start_iteration = 1\n",
    "        print_loss = 0\n",
    "\n",
    "        train_loss = []\n",
    "        train_loss_sum = []\n",
    "\n",
    "        # Training loop\n",
    "        c_encoder.train()\n",
    "        i = 0\n",
    "        n_iteration = len(training_data)\n",
    "        shuffle_list(training_data)\n",
    "        for data in training_data:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            context, response, label = data\n",
    "            context_ids = load_id(context, word_to_id)\n",
    "            response_ids = load_id(response, word_to_id)\n",
    "            \n",
    "            # Run a training iteration with batch\n",
    "            output = c_encoder(context_ids, response_ids)\n",
    "            output = output.squeeze(0)\n",
    "\n",
    "            # loss backward\n",
    "            labl = autograd.Variable(torch.LongTensor([label]), requires_grad = False)#torch.LongTensor(label)\n",
    "            labl = labl.to(device)\n",
    "            loss = loss_func(output, labl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.data.cpu())\n",
    "            train_loss_sum.append(loss.data.cpu())\n",
    "\n",
    "            # Print progress\n",
    "            print_loss += loss\n",
    "            if i % 5000 == 0:\n",
    "                print_loss_avg = print_loss / 5000\n",
    "                print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}; Mean train loss: {:.4f}\".format(i, i / n_iteration * 100, print_loss_avg, np.mean(train_loss)))\n",
    "                print_loss = 0\n",
    "                train_loss = []\n",
    "            i += 1\n",
    "            \n",
    "        # Record at every epoch\n",
    "        print('Train Loss at epoch{}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "        train_loss_list.append(np.mean(train_loss_sum))\n",
    "        \n",
    "        c_encoder.eval()\n",
    "        print(\"Going through validation data\")\n",
    "        # Iterate through validation set\n",
    "        sum_loss_validation = []\n",
    "        shuffle_list(validation_data)\n",
    "        for data in validation_data:\n",
    "            \n",
    "            context, response, label = data\n",
    "            context_ids = load_id(context, word_to_id)\n",
    "            response_ids = load_id(response, word_to_id)\n",
    "            \n",
    "            # Run a validation iteration with batch\n",
    "            output = c_encoder(context_ids, response_ids)\n",
    "            output = output.squeeze(0)\n",
    "            \n",
    "            # loss\n",
    "            labl = autograd.Variable(torch.LongTensor([label]), requires_grad = False)\n",
    "            labl = labl.to(device)\n",
    "            loss = loss_func(output, labl)\n",
    "            sum_loss_validation.append(loss.data.cpu())\n",
    "            \n",
    "        print(\"Validation loss: {:.4f}\".format(np.mean(sum_loss_validation)))\n",
    "        validation_loss_list.append(np.mean(sum_loss_validation))\n",
    "\n",
    "        print(str(datetime.datetime.now()).split('.')[0], \n",
    "              \"Epoch: %d/%d\" %(epoch,epochs))\n",
    "\n",
    "        # Saving best result\n",
    "        if np.mean(sum_loss_validation) < best_loss:\n",
    "            best_record = np.mean(sum_loss_validation)\n",
    "            print(\"Saving new best\")\n",
    "            torch.save({\n",
    "                        'en': c_encoder.state_dict(),\n",
    "                        'opt': optimizer.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                        't_loss': train_loss_list,\n",
    "                        'v_loss': validation_loss_list,\n",
    "                        'voc_dict': voc.__dict__\n",
    "                }, os.path.join('saveDir', 'retrieval_model1.tar'))\n",
    "        # Save checkpoint after each epoch\n",
    "        torch.save({\n",
    "                'en': c_encoder.state_dict(),\n",
    "                'opt': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                't_loss': train_loss_list,\n",
    "                'v_loss': validation_loss_list,\n",
    "                'voc_dict': voc.__dict__\n",
    "            }, os.path.join('saveDir', '{}_{}.tar'.format('retrieval_model', epoch)))\n",
    "            \n",
    "    print(str(datetime.datetime.now()).split('.')[0], \"Training and validation epochs finished.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02080fed-d81e-4a15-bb54-c4613ad05587",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'saveDir/save_temp.tar'\n",
    "temp1 = Temp()\n",
    "temp1.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6880bf9a-d2b6-470e-ac12-8925a0196e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n_iteration = 8000\n",
    "#batch_size = 64\n",
    "#training_data, validation_data, voc = prepareData(50)\n",
    "training_data = temp1.training\n",
    "validation_data = temp1.validation\n",
    "voc = temp1.voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8712c1e-8caa-45fb-ad44-deed54232cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68522"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6509b2b9-10f6-424e-af99-5f00ac87a1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "hidden_size = 50\n",
    "vocab_size = len(voc.vocab)\n",
    "id_to_vec = voc.id2vec\n",
    "layers = 1\n",
    "bi_dir = 1\n",
    "encoder, dual_encoder = creating_model(embed_size, hidden_size, layers, bi_dir, vocab_size, id_to_vec, dropout = 0.1)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "dual_encoder = dual_encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "372e3de3-8852-4179-a5c9-71117cd39df4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved checkpoint\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0009\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1892; Mean train loss: 0.1892\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.2109; Mean train loss: 0.2109\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.2130; Mean train loss: 0.2130\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.2071; Mean train loss: 0.2071\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.2087; Mean train loss: 0.2087\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.2027; Mean train loss: 0.2027\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.2093; Mean train loss: 0.2093\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.2002; Mean train loss: 0.2002\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1897; Mean train loss: 0.1897\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.2083; Mean train loss: 0.2083\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.2155; Mean train loss: 0.2155\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.2044; Mean train loss: 0.2044\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.2192; Mean train loss: 0.2192\n",
      "Train Loss at epoch9: 0.2064111828804016\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2375\n",
      "2021-12-19 13:19:17 Epoch: 9/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0199\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.2029; Mean train loss: 0.2029\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1943; Mean train loss: 0.1943\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1917; Mean train loss: 0.1917\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.2034; Mean train loss: 0.2034\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1938; Mean train loss: 0.1938\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.2127; Mean train loss: 0.2127\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.2082; Mean train loss: 0.2082\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.2024; Mean train loss: 0.2024\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.2055; Mean train loss: 0.2055\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1964; Mean train loss: 0.1964\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1964; Mean train loss: 0.1964\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.2054; Mean train loss: 0.2054\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1958; Mean train loss: 0.1958\n",
      "Train Loss at epoch10: 0.20121517777442932\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2369\n",
      "2021-12-19 13:30:19 Epoch: 10/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0007\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1956; Mean train loss: 0.1956\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.2105; Mean train loss: 0.2105\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1900; Mean train loss: 0.1900\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.2065; Mean train loss: 0.2065\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.2012; Mean train loss: 0.2012\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.2018; Mean train loss: 0.2018\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1988; Mean train loss: 0.1988\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.2042; Mean train loss: 0.2042\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1825; Mean train loss: 0.1825\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1985; Mean train loss: 0.1985\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1939; Mean train loss: 0.1939\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1850; Mean train loss: 0.1850\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.2112; Mean train loss: 0.2112\n",
      "Train Loss at epoch11: 0.1979641169309616\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2396\n",
      "2021-12-19 13:41:32 Epoch: 11/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0180\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1810; Mean train loss: 0.1810\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1921; Mean train loss: 0.1921\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1988; Mean train loss: 0.1988\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.2023; Mean train loss: 0.2023\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1931; Mean train loss: 0.1931\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1899; Mean train loss: 0.1899\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1813; Mean train loss: 0.1813\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1945; Mean train loss: 0.1945\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1928; Mean train loss: 0.1928\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.2013; Mean train loss: 0.2013\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.2005; Mean train loss: 0.2005\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1884; Mean train loss: 0.1884\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1948; Mean train loss: 0.1948\n",
      "Train Loss at epoch12: 0.19368596374988556\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2340\n",
      "2021-12-19 13:52:32 Epoch: 12/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0255\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1989; Mean train loss: 0.1989\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1808; Mean train loss: 0.1808\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1894; Mean train loss: 0.1894\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1904; Mean train loss: 0.1904\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1879; Mean train loss: 0.1879\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1978; Mean train loss: 0.1978\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1925; Mean train loss: 0.1925\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1953; Mean train loss: 0.1953\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.2023; Mean train loss: 0.2023\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1884; Mean train loss: 0.1884\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1856; Mean train loss: 0.1856\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1833; Mean train loss: 0.1833\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1998; Mean train loss: 0.1998\n",
      "Train Loss at epoch13: 0.19232763350009918\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2375\n",
      "2021-12-19 14:04:01 Epoch: 13/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0389\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1854; Mean train loss: 0.1854\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1905; Mean train loss: 0.1905\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1848; Mean train loss: 0.1848\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1811; Mean train loss: 0.1811\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1894; Mean train loss: 0.1894\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1900; Mean train loss: 0.1900\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1805; Mean train loss: 0.1805\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1959; Mean train loss: 0.1959\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1899; Mean train loss: 0.1899\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1956; Mean train loss: 0.1956\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1890; Mean train loss: 0.1890\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1822; Mean train loss: 0.1822\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1863; Mean train loss: 0.1863\n",
      "Train Loss at epoch14: 0.1875583827495575\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2467\n",
      "2021-12-19 14:15:57 Epoch: 14/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0000\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1771; Mean train loss: 0.1771\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1795; Mean train loss: 0.1795\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1838; Mean train loss: 0.1838\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1907; Mean train loss: 0.1907\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1820; Mean train loss: 0.1820\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1939; Mean train loss: 0.1939\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1853; Mean train loss: 0.1853\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1778; Mean train loss: 0.1778\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1915; Mean train loss: 0.1915\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1732; Mean train loss: 0.1732\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1888; Mean train loss: 0.1888\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1861; Mean train loss: 0.1861\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1893; Mean train loss: 0.1893\n",
      "Train Loss at epoch15: 0.1852668970823288\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2432\n",
      "2021-12-19 14:27:35 Epoch: 15/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0085\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1696; Mean train loss: 0.1696\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1843; Mean train loss: 0.1843\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1867; Mean train loss: 0.1867\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1823; Mean train loss: 0.1823\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1753; Mean train loss: 0.1753\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1796; Mean train loss: 0.1796\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1676; Mean train loss: 0.1676\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1856; Mean train loss: 0.1856\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1728; Mean train loss: 0.1728\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1871; Mean train loss: 0.1871\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1912; Mean train loss: 0.1912\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1770; Mean train loss: 0.1770\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1873; Mean train loss: 0.1873\n",
      "Train Loss at epoch16: 0.18051770329475403\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2372\n",
      "2021-12-19 14:41:22 Epoch: 16/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0433\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1714; Mean train loss: 0.1714\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1683; Mean train loss: 0.1683\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1710; Mean train loss: 0.1710\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1821; Mean train loss: 0.1821\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1785; Mean train loss: 0.1785\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1793; Mean train loss: 0.1793\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1801; Mean train loss: 0.1801\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1716; Mean train loss: 0.1716\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1785; Mean train loss: 0.1785\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1807; Mean train loss: 0.1807\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1805; Mean train loss: 0.1805\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1749; Mean train loss: 0.1749\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1898; Mean train loss: 0.1898\n",
      "Train Loss at epoch17: 0.1778486669063568\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2339\n",
      "2021-12-19 14:55:49 Epoch: 17/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0000; Mean train loss: 0.0810\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1629; Mean train loss: 0.1629\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1626; Mean train loss: 0.1626\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1684; Mean train loss: 0.1684\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1828; Mean train loss: 0.1828\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1740; Mean train loss: 0.1740\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1737; Mean train loss: 0.1737\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1814; Mean train loss: 0.1814\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1656; Mean train loss: 0.1656\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1779; Mean train loss: 0.1779\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1833; Mean train loss: 0.1833\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1827; Mean train loss: 0.1827\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1712; Mean train loss: 0.1712\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1799; Mean train loss: 0.1799\n",
      "Train Loss at epoch18: 0.17406783998012543\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2504\n",
      "2021-12-19 15:07:58 Epoch: 18/20\n",
      "Saving new best\n",
      "Iteration: 0; Percent complete: 0.0%; Average loss: 0.0003; Mean train loss: 1.6356\n",
      "Iteration: 5000; Percent complete: 7.3%; Average loss: 0.1639; Mean train loss: 0.1639\n",
      "Iteration: 10000; Percent complete: 14.6%; Average loss: 0.1755; Mean train loss: 0.1755\n",
      "Iteration: 15000; Percent complete: 21.9%; Average loss: 0.1767; Mean train loss: 0.1767\n",
      "Iteration: 20000; Percent complete: 29.2%; Average loss: 0.1769; Mean train loss: 0.1769\n",
      "Iteration: 25000; Percent complete: 36.5%; Average loss: 0.1762; Mean train loss: 0.1762\n",
      "Iteration: 30000; Percent complete: 43.8%; Average loss: 0.1712; Mean train loss: 0.1712\n",
      "Iteration: 35000; Percent complete: 51.1%; Average loss: 0.1764; Mean train loss: 0.1764\n",
      "Iteration: 40000; Percent complete: 58.4%; Average loss: 0.1740; Mean train loss: 0.1740\n",
      "Iteration: 45000; Percent complete: 65.7%; Average loss: 0.1738; Mean train loss: 0.1738\n",
      "Iteration: 50000; Percent complete: 73.0%; Average loss: 0.1738; Mean train loss: 0.1738\n",
      "Iteration: 55000; Percent complete: 80.3%; Average loss: 0.1697; Mean train loss: 0.1697\n",
      "Iteration: 60000; Percent complete: 87.6%; Average loss: 0.1773; Mean train loss: 0.1773\n",
      "Iteration: 65000; Percent complete: 94.9%; Average loss: 0.1616; Mean train loss: 0.1616\n",
      "Train Loss at epoch19: 0.17228884994983673\n",
      "\n",
      "Going through validation data\n",
      "Validation loss: 0.2550\n",
      "2021-12-19 15:19:52 Epoch: 19/20\n",
      "Saving new best\n",
      "2021-12-19 15:19:53 Training and validation epochs finished.\n"
     ]
    }
   ],
   "source": [
    "trainIterAll(training_data = training_data, validation_data = validation_data, voc = voc, c_encoder = dual_encoder, learning_rate = 0.0001, l2_penalty = 0.000001, epochs = 20, filename='saveDir/retrieval_model.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfc7816d-7476-4ac9-aa2b-2e6e037d3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('SaveDir/retrieval_model_12.tar')\n",
    "train_loss_list = checkpoint['t_loss']\n",
    "validation_loss_list = checkpoint['v_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ab658bed-b990-4b3e-b062-dc9566eef154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, label='train')\n",
    "plt.plot(validation_loss_list, label='val')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe105bc-2be0-4832-a0c6-4df2cd7e915b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
